{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNvhqStdHQCEfyXutyzuRT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaquelinedops/Benchmarking_NER/blob/main/Benchmarking_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG9YOpQ8sWAy",
        "outputId": "175a3cef-c21a-443c-943c-d649358070f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V0qzWU3FojfZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "from seqeval.metrics import classification_report\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "# Load the conll2003 dataset\n",
        "ds, info = tfds.load(\n",
        "    'conll2003',\n",
        "    split=['train', 'test'], # The splits are 'train', 'validation', and 'test'\n",
        "    with_info=True,\n",
        "    as_supervised=False # Set to True if you want a (features, label) tuple\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ds[0]\n",
        "test_ds = ds[1]"
      ],
      "metadata": {
        "id": "lGXVQIrIpLoD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this to check for CUDA availability and move all related calls inside\n",
        "print(\"Is CUDA available?:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Total VRAM:\", round(torch.cuda.get_device_properties(0).total_memory / 1024**3, 2), \"GB\")\n",
        "else:\n",
        "    print(\"CUDA not available. GPU not detected.\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIiSKUUmrt2_",
        "outputId": "2d480026-8f2c-46ae-a069-dcea11cbdd4a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is CUDA available?: True\n",
            "GPU Name: Tesla T4\n",
            "Total VRAM: 14.74 GB\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    dataset_tfds, info = tfds.load(\n",
        "        \"conll2003\",\n",
        "        split='test',\n",
        "        as_supervised=False,\n",
        "        with_info=True\n",
        "    )\n",
        "    test_ds = dataset_tfds\n",
        "    label_list = info.features['ner'].feature.names\n",
        "    print(\"Dataset 'conll2003' loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Dicionário de modelos para o benchmark\n",
        "modelos = {\n",
        "    \"XML-RoBERTa\": \"Davlan/xlm-roberta-base-ner-hrl\",\n",
        "    \"BERT-Davlan\": \"Davlan/bert-base-multilingual-cased-ner-hrl\",\n",
        "    \"BERT\": \"dslim/bert-base-NER\",\n",
        "    \"RoBERTa\": \"Jean-Baptiste/roberta-large-ner-english\",\n",
        "}\n",
        "\n",
        "# --- Seção 2: Função para Avaliação ---\n",
        "\n",
        "def avaliar_modelo_ner(model_name, dataset_para_teste, label_list, device):\n",
        "    \"\"\"\n",
        "    Carrega um modelo e seu tokenizer, roda o pipeline de NER\n",
        "    no dataset de teste e retorna um relatório de classificação detalhado\n",
        "    e o score Cohen's Kappa.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Avaliando o Modelo: {model_name} ---\")\n",
        "\n",
        "    # Carrega o tokenizer e o modelo\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(model_name).to(device)\n",
        "\n",
        "    # Cria o pipeline de NER, passando o dispositivo explicitamente\n",
        "    device_id = 0 if device.type == 'cuda' else -1\n",
        "    ner_pipeline = pipeline(\n",
        "        \"ner\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        aggregation_strategy=\"simple\",\n",
        "        device=device_id\n",
        "    )\n",
        "\n",
        "    # Listas para armazenar as entidades preditas e as verdadeiras\n",
        "    # We will need two sets of lists: one for seqeval and one flattened for Cohen's Kappa\n",
        "    verdades_seqeval = []\n",
        "    predicoes_seqeval = []\n",
        "\n",
        "    verdades_flattened = []\n",
        "    predicoes_flattened = []\n",
        "\n",
        "    # Processa cada exemplo no dataset de teste\n",
        "    for exemplo in dataset_para_teste:\n",
        "        tokens = [t.decode('utf-8') for t in exemplo['tokens'].numpy().tolist()]\n",
        "        tags_verdadeiras_ids = exemplo['ner'].numpy().tolist()\n",
        "\n",
        "        # Map the true tags from numbers to names for seqeval\n",
        "        tags_verdadeiras_str = [label_list[tag_id] for tag_id in tags_verdadeiras_ids]\n",
        "\n",
        "        texto = \" \".join(tokens)\n",
        "        preds = ner_pipeline(texto)\n",
        "\n",
        "        # Format predictions for seqeval and flatten for Cohen's Kappa\n",
        "        preds_seq_level = ['O'] * len(tokens)\n",
        "        preds_kappa_level = ['O'] * len(tokens) # We'll start with 'O' tags\n",
        "\n",
        "        # Logic to map the aggregated pipeline predictions to the token-level format\n",
        "        # This part of your code seems complex and potentially brittle.\n",
        "        # A more robust approach might be to not use the 'simple' aggregation\n",
        "        # and process token-level predictions directly from the model output,\n",
        "        # but for now, we'll try to keep your logic and ensure it provides\n",
        "        # a flattened list for Kappa.\n",
        "\n",
        "        current_char_idx = 0\n",
        "        for pred in preds:\n",
        "            word = pred['word']\n",
        "            entity_type = pred['entity_group']\n",
        "\n",
        "            # This is your token mapping logic. Let's assume it works for now.\n",
        "            token_start_index = -1\n",
        "            temp_text = \"\"\n",
        "            for i, token in enumerate(tokens):\n",
        "                if word.startswith(temp_text + token):\n",
        "                    if token_start_index == -1:\n",
        "                        token_start_index = i\n",
        "                    temp_text += token\n",
        "                    if temp_text == word:\n",
        "                        break\n",
        "                else:\n",
        "                    temp_text = \"\"\n",
        "                    token_start_index = -1\n",
        "\n",
        "            if token_start_index != -1:\n",
        "                preds_seq_level[token_start_index] = f\"B-{entity_type}\"\n",
        "                preds_kappa_level[token_start_index] = f\"B-{entity_type}\" # Save for Kappa\n",
        "                for i in range(token_start_index + 1, len(tokens)):\n",
        "                    if word.endswith(\"\".join(tokens[token_start_index:i+1])):\n",
        "                        preds_seq_level[i] = f\"I-{entity_type}\"\n",
        "                        preds_kappa_level[i] = f\"I-{entity_type}\" # Save for Kappa\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "        verdades_seqeval.append(tags_verdadeiras_str)\n",
        "        predicoes_seqeval.append(preds_seq_level)\n",
        "\n",
        "        verdades_flattened.extend(tags_verdadeiras_str)\n",
        "        predicoes_flattened.extend(preds_kappa_level)\n",
        "\n",
        "    # Generate the detailed classification report\n",
        "    relatorio = classification_report(verdades_seqeval, predicoes_seqeval, digits=5, output_dict=True)\n",
        "\n",
        "    # Calculate Cohen's Kappa\n",
        "    kappa = cohen_kappa_score(verdades_flattened, predicoes_flattened)\n",
        "\n",
        "    return relatorio, kappa\n",
        "\n",
        "# --- Seção 3: Execução do Benchmark e Exibição dos Resultados ---\n",
        "\n",
        "# Detectar o dispositivo disponível (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "relatorio_final = []\n",
        "for nome_modelo, model_id in modelos.items():\n",
        "    relatorio, kappa_score = avaliar_modelo_ner(model_id, test_ds, label_list, device)\n",
        "    df_relatorio = pd.DataFrame(relatorio).transpose()\n",
        "    df_relatorio = df_relatorio.round(4)\n",
        "    print(f\"\\n=====================================================\")\n",
        "    print(f\"RELATÓRIO DE AVALIAÇÃO PARA O MODELO: {nome_modelo}\")\n",
        "    print(df_relatorio)\n",
        "    print(\"=====================================================\")\n",
        "    print(\"=====================================================\")\n",
        "    print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
        "    print(\"=====================================================\\n\")\n",
        "    relatorio_final.append(relatorio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z8v9Tz5rYtE",
        "outputId": "01c1d6ab-8e2e-4ec1-f232-16883cb28bf3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'conll2003' loaded successfully.\n",
            "Using device: cuda\n",
            "\n",
            "--- Avaliando o Modelo: Davlan/xlm-roberta-base-ner-hrl ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====================================================\n",
            "RELATÓRIO DE AVALIAÇÃO PARA O MODELO: XML-RoBERTa\n",
            "              precision  recall  f1-score  support\n",
            "LOC              0.9578  0.7614    0.8484   1668.0\n",
            "MISC             0.0000  0.0000    0.0000    702.0\n",
            "ORG              0.8925  0.5250    0.6611   1661.0\n",
            "PER              0.9202  0.2566    0.4014   1617.0\n",
            "micro avg        0.9285  0.4527    0.6087   5648.0\n",
            "macro avg        0.6926  0.3858    0.4777   5648.0\n",
            "weighted avg     0.8088  0.4527    0.5599   5648.0\n",
            "=====================================================\n",
            "=====================================================\n",
            "Cohen's Kappa Score: 0.4547\n",
            "=====================================================\n",
            "\n",
            "\n",
            "--- Avaliando o Modelo: Davlan/bert-base-multilingual-cased-ner-hrl ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====================================================\n",
            "RELATÓRIO DE AVALIAÇÃO PARA O MODELO: BERT-Davlan\n",
            "              precision  recall  f1-score  support\n",
            "LOC              0.9432  0.7560    0.8393   1668.0\n",
            "MISC             0.0000  0.0000    0.0000    702.0\n",
            "ORG              0.8874  0.5647    0.6902   1661.0\n",
            "PER              0.9367  0.2746    0.4247   1617.0\n",
            "micro avg        0.9215  0.4680    0.6207   5648.0\n",
            "macro avg        0.6918  0.3988    0.4885   5648.0\n",
            "weighted avg     0.8077  0.4680    0.5724   5648.0\n",
            "=====================================================\n",
            "=====================================================\n",
            "Cohen's Kappa Score: 0.4688\n",
            "=====================================================\n",
            "\n",
            "\n",
            "--- Avaliando o Modelo: dslim/bert-base-NER ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====================================================\n",
            "RELATÓRIO DE AVALIAÇÃO PARA O MODELO: BERT\n",
            "              precision  recall  f1-score  support\n",
            "LOC              0.9457  0.6781    0.7898   1668.0\n",
            "MISC             0.8665  0.5271    0.6554    702.0\n",
            "ORG              0.8927  0.5111    0.6501   1661.0\n",
            "PER              0.9425  0.1824    0.3057   1617.0\n",
            "micro avg        0.9162  0.4683    0.6198   5648.0\n",
            "macro avg        0.9118  0.4747    0.6003   5648.0\n",
            "weighted avg     0.9194  0.4683    0.5934   5648.0\n",
            "=====================================================\n",
            "=====================================================\n",
            "Cohen's Kappa Score: 0.4693\n",
            "=====================================================\n",
            "\n",
            "\n",
            "--- Avaliando o Modelo: Jean-Baptiste/roberta-large-ner-english ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====================================================\n",
            "RELATÓRIO DE AVALIAÇÃO PARA O MODELO: RoBERTa\n",
            "              precision  recall  f1-score  support\n",
            "LOC                 0.0     0.0       0.0   1668.0\n",
            "MISC                0.0     0.0       0.0    702.0\n",
            "ORG                 0.0     0.0       0.0   1661.0\n",
            "PER                 0.0     0.0       0.0   1617.0\n",
            "micro avg           0.0     0.0       0.0   5648.0\n",
            "macro avg           0.0     0.0       0.0   5648.0\n",
            "weighted avg        0.0     0.0       0.0   5648.0\n",
            "=====================================================\n",
            "=====================================================\n",
            "Cohen's Kappa Score: -0.0000\n",
            "=====================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}